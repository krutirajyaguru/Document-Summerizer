[2023-05-16T13:45:52.071+0200] {processor.py:156} INFO - Started process (PID=75520) to work on /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T13:45:52.077+0200] {processor.py:799} INFO - Processing file /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py for tasks to queue
[2023-05-16T13:45:52.077+0200] {logging_mixin.py:149} INFO - [2023-05-16T13:45:52.077+0200] {dagbag.py:541} INFO - Filling up the DagBag from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T13:45:53.852+0200] {logging_mixin.py:149} INFO - [2023-05-16T13:45:53.852+0200] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2023-05-16T13:45:59.925+0200] {processor.py:809} INFO - DAG(s) dict_keys(['etl_news_pipeline']) retrieved from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T13:46:04.461+0200] {logging_mixin.py:149} INFO - [2023-05-16T13:46:04.461+0200] {dag.py:2726} INFO - Sync 1 DAGs
[2023-05-16T13:46:04.573+0200] {processor.py:178} INFO - Processing /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py took 12.504 seconds
[2023-05-16T13:46:46.748+0200] {processor.py:156} INFO - Started process (PID=75890) to work on /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T13:46:46.774+0200] {processor.py:799} INFO - Processing file /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py for tasks to queue
[2023-05-16T13:46:46.774+0200] {logging_mixin.py:149} INFO - [2023-05-16T13:46:46.774+0200] {dagbag.py:541} INFO - Filling up the DagBag from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T13:46:48.622+0200] {logging_mixin.py:149} INFO - [2023-05-16T13:46:48.622+0200] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2023-05-16T13:46:54.422+0200] {processor.py:809} INFO - DAG(s) dict_keys(['etl_news_pipeline']) retrieved from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T13:46:57.120+0200] {logging_mixin.py:149} INFO - [2023-05-16T13:46:57.119+0200] {dag.py:2726} INFO - Sync 1 DAGs
[2023-05-16T13:46:57.195+0200] {processor.py:178} INFO - Processing /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py took 10.448 seconds
[2023-05-16T13:50:37.544+0200] {processor.py:156} INFO - Started process (PID=1437) to work on /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T13:50:37.547+0200] {processor.py:799} INFO - Processing file /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py for tasks to queue
[2023-05-16T13:50:37.548+0200] {logging_mixin.py:149} INFO - [2023-05-16T13:50:37.548+0200] {dagbag.py:541} INFO - Filling up the DagBag from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T13:50:40.806+0200] {logging_mixin.py:149} INFO - [2023-05-16T13:50:40.806+0200] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2023-05-16T13:50:44.339+0200] {processor.py:809} INFO - DAG(s) dict_keys(['etl_news_pipeline']) retrieved from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T13:50:45.097+0200] {logging_mixin.py:149} INFO - [2023-05-16T13:50:45.097+0200] {dag.py:2726} INFO - Sync 1 DAGs
[2023-05-16T13:50:45.114+0200] {logging_mixin.py:149} INFO - [2023-05-16T13:50:45.114+0200] {dag.py:3486} INFO - Setting next_dagrun for etl_news_pipeline to 2023-05-15T00:00:00+00:00, run_after=2023-05-16T00:00:00+00:00
[2023-05-16T13:50:45.129+0200] {processor.py:178} INFO - Processing /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py took 7.586 seconds
[2023-05-16T13:51:17.035+0200] {processor.py:156} INFO - Started process (PID=1542) to work on /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T13:51:17.039+0200] {processor.py:799} INFO - Processing file /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py for tasks to queue
[2023-05-16T13:51:17.039+0200] {logging_mixin.py:149} INFO - [2023-05-16T13:51:17.039+0200] {dagbag.py:541} INFO - Filling up the DagBag from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T13:51:17.504+0200] {logging_mixin.py:149} INFO - [2023-05-16T13:51:17.503+0200] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2023-05-16T13:51:19.546+0200] {processor.py:809} INFO - DAG(s) dict_keys(['etl_news_pipeline']) retrieved from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T13:51:21.003+0200] {logging_mixin.py:149} INFO - [2023-05-16T13:51:21.002+0200] {dag.py:2726} INFO - Sync 1 DAGs
[2023-05-16T13:51:21.022+0200] {logging_mixin.py:149} INFO - [2023-05-16T13:51:21.022+0200] {dag.py:3486} INFO - Setting next_dagrun for etl_news_pipeline to 2023-05-16T00:00:00+00:00, run_after=2023-05-17T00:00:00+00:00
[2023-05-16T13:51:21.045+0200] {processor.py:178} INFO - Processing /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py took 4.010 seconds
[2023-05-16T13:51:52.606+0200] {processor.py:156} INFO - Started process (PID=1707) to work on /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T13:51:52.608+0200] {processor.py:799} INFO - Processing file /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py for tasks to queue
[2023-05-16T13:51:52.609+0200] {logging_mixin.py:149} INFO - [2023-05-16T13:51:52.609+0200] {dagbag.py:541} INFO - Filling up the DagBag from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T13:51:52.955+0200] {logging_mixin.py:149} INFO - [2023-05-16T13:51:52.955+0200] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2023-05-16T13:51:54.276+0200] {processor.py:809} INFO - DAG(s) dict_keys(['etl_news_pipeline']) retrieved from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T13:51:55.157+0200] {logging_mixin.py:149} INFO - [2023-05-16T13:51:55.156+0200] {dag.py:2726} INFO - Sync 1 DAGs
[2023-05-16T13:51:55.174+0200] {logging_mixin.py:149} INFO - [2023-05-16T13:51:55.174+0200] {dag.py:3486} INFO - Setting next_dagrun for etl_news_pipeline to 2023-05-16T00:00:00+00:00, run_after=2023-05-17T00:00:00+00:00
[2023-05-16T13:51:55.191+0200] {processor.py:178} INFO - Processing /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py took 2.586 seconds
[2023-05-16T13:52:26.516+0200] {processor.py:156} INFO - Started process (PID=1762) to work on /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T13:52:26.519+0200] {processor.py:799} INFO - Processing file /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py for tasks to queue
[2023-05-16T13:52:26.519+0200] {logging_mixin.py:149} INFO - [2023-05-16T13:52:26.519+0200] {dagbag.py:541} INFO - Filling up the DagBag from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T13:52:26.860+0200] {logging_mixin.py:149} INFO - [2023-05-16T13:52:26.860+0200] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2023-05-16T13:52:28.129+0200] {processor.py:809} INFO - DAG(s) dict_keys(['etl_news_pipeline']) retrieved from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T13:52:28.843+0200] {logging_mixin.py:149} INFO - [2023-05-16T13:52:28.843+0200] {dag.py:2726} INFO - Sync 1 DAGs
[2023-05-16T13:52:28.850+0200] {logging_mixin.py:149} INFO - [2023-05-16T13:52:28.850+0200] {dag.py:2747} INFO - Creating ORM DAG for etl_news_pipeline
[2023-05-16T13:52:28.856+0200] {logging_mixin.py:149} INFO - [2023-05-16T13:52:28.856+0200] {dag.py:3486} INFO - Setting next_dagrun for etl_news_pipeline to 2023-05-14T00:00:00+00:00, run_after=2023-05-15T00:00:00+00:00
[2023-05-16T13:52:28.872+0200] {processor.py:178} INFO - Processing /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py took 2.356 seconds
[2023-05-16T13:52:52.572+0200] {processor.py:156} INFO - Started process (PID=1837) to work on /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T13:52:52.575+0200] {processor.py:799} INFO - Processing file /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py for tasks to queue
[2023-05-16T13:52:52.575+0200] {logging_mixin.py:149} INFO - [2023-05-16T13:52:52.575+0200] {dagbag.py:541} INFO - Filling up the DagBag from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T13:52:52.896+0200] {logging_mixin.py:149} INFO - [2023-05-16T13:52:52.895+0200] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2023-05-16T13:52:54.176+0200] {processor.py:809} INFO - DAG(s) dict_keys(['etl_news_pipeline']) retrieved from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T13:52:54.231+0200] {logging_mixin.py:149} INFO - [2023-05-16T13:52:54.231+0200] {dag.py:2726} INFO - Sync 1 DAGs
[2023-05-16T13:52:54.838+0200] {logging_mixin.py:149} INFO - [2023-05-16T13:52:54.838+0200] {dag.py:3486} INFO - Setting next_dagrun for etl_news_pipeline to 2023-05-14T00:00:00+00:00, run_after=2023-05-15T00:00:00+00:00
[2023-05-16T13:52:54.855+0200] {processor.py:178} INFO - Processing /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py took 2.283 seconds
[2023-05-16T13:53:26.186+0200] {processor.py:156} INFO - Started process (PID=1885) to work on /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T13:53:26.189+0200] {processor.py:799} INFO - Processing file /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py for tasks to queue
[2023-05-16T13:53:26.189+0200] {logging_mixin.py:149} INFO - [2023-05-16T13:53:26.189+0200] {dagbag.py:541} INFO - Filling up the DagBag from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T13:53:26.502+0200] {logging_mixin.py:149} INFO - [2023-05-16T13:53:26.502+0200] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2023-05-16T13:53:27.791+0200] {processor.py:809} INFO - DAG(s) dict_keys(['etl_news_pipeline']) retrieved from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T13:53:28.446+0200] {logging_mixin.py:149} INFO - [2023-05-16T13:53:28.446+0200] {dag.py:2726} INFO - Sync 1 DAGs
[2023-05-16T13:53:28.460+0200] {logging_mixin.py:149} INFO - [2023-05-16T13:53:28.459+0200] {dag.py:3486} INFO - Setting next_dagrun for etl_news_pipeline to 2023-05-14T00:00:00+00:00, run_after=2023-05-15T00:00:00+00:00
[2023-05-16T13:53:28.472+0200] {processor.py:178} INFO - Processing /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py took 2.286 seconds
[2023-05-16T13:53:59.818+0200] {processor.py:156} INFO - Started process (PID=1925) to work on /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T13:53:59.820+0200] {processor.py:799} INFO - Processing file /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py for tasks to queue
[2023-05-16T13:53:59.820+0200] {logging_mixin.py:149} INFO - [2023-05-16T13:53:59.820+0200] {dagbag.py:541} INFO - Filling up the DagBag from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T13:54:00.145+0200] {logging_mixin.py:149} INFO - [2023-05-16T13:54:00.145+0200] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2023-05-16T13:54:01.397+0200] {processor.py:809} INFO - DAG(s) dict_keys(['etl_news_pipeline']) retrieved from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T13:54:02.085+0200] {logging_mixin.py:149} INFO - [2023-05-16T13:54:02.084+0200] {dag.py:2726} INFO - Sync 1 DAGs
[2023-05-16T13:54:02.111+0200] {logging_mixin.py:149} INFO - [2023-05-16T13:54:02.111+0200] {dag.py:3486} INFO - Setting next_dagrun for etl_news_pipeline to 2023-05-14T00:00:00+00:00, run_after=2023-05-15T00:00:00+00:00
[2023-05-16T13:54:02.132+0200] {processor.py:178} INFO - Processing /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py took 2.315 seconds
[2023-05-16T13:54:33.777+0200] {processor.py:156} INFO - Started process (PID=1965) to work on /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T13:54:33.779+0200] {processor.py:799} INFO - Processing file /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py for tasks to queue
[2023-05-16T13:54:33.779+0200] {logging_mixin.py:149} INFO - [2023-05-16T13:54:33.779+0200] {dagbag.py:541} INFO - Filling up the DagBag from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T13:54:34.220+0200] {logging_mixin.py:149} INFO - [2023-05-16T13:54:34.220+0200] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2023-05-16T13:54:35.837+0200] {processor.py:809} INFO - DAG(s) dict_keys(['etl_news_pipeline']) retrieved from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T13:54:37.079+0200] {logging_mixin.py:149} INFO - [2023-05-16T13:54:37.079+0200] {dag.py:2726} INFO - Sync 1 DAGs
[2023-05-16T13:54:37.097+0200] {logging_mixin.py:149} INFO - [2023-05-16T13:54:37.097+0200] {dag.py:3486} INFO - Setting next_dagrun for etl_news_pipeline to 2023-05-16T00:00:00+00:00, run_after=2023-05-17T00:00:00+00:00
[2023-05-16T13:54:37.116+0200] {processor.py:178} INFO - Processing /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py took 3.340 seconds
[2023-05-16T13:55:09.502+0200] {processor.py:156} INFO - Started process (PID=2076) to work on /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T13:55:09.507+0200] {processor.py:799} INFO - Processing file /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py for tasks to queue
[2023-05-16T13:55:09.507+0200] {logging_mixin.py:149} INFO - [2023-05-16T13:55:09.507+0200] {dagbag.py:541} INFO - Filling up the DagBag from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T13:55:10.355+0200] {logging_mixin.py:149} INFO - [2023-05-16T13:55:10.355+0200] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2023-05-16T13:55:13.204+0200] {processor.py:809} INFO - DAG(s) dict_keys(['etl_news_pipeline']) retrieved from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T13:55:14.877+0200] {logging_mixin.py:149} INFO - [2023-05-16T13:55:14.876+0200] {dag.py:2726} INFO - Sync 1 DAGs
[2023-05-16T13:55:14.897+0200] {logging_mixin.py:149} INFO - [2023-05-16T13:55:14.897+0200] {dag.py:3486} INFO - Setting next_dagrun for etl_news_pipeline to 2023-05-16T00:00:00+00:00, run_after=2023-05-17T00:00:00+00:00
[2023-05-16T13:55:14.931+0200] {processor.py:178} INFO - Processing /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py took 5.429 seconds
[2023-05-16T13:55:47.467+0200] {processor.py:156} INFO - Started process (PID=2180) to work on /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T13:55:47.471+0200] {processor.py:799} INFO - Processing file /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py for tasks to queue
[2023-05-16T13:55:47.471+0200] {logging_mixin.py:149} INFO - [2023-05-16T13:55:47.471+0200] {dagbag.py:541} INFO - Filling up the DagBag from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T13:55:48.232+0200] {logging_mixin.py:149} INFO - [2023-05-16T13:55:48.222+0200] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2023-05-16T13:55:52.207+0200] {processor.py:809} INFO - DAG(s) dict_keys(['etl_news_pipeline']) retrieved from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T13:55:54.266+0200] {logging_mixin.py:149} INFO - [2023-05-16T13:55:54.265+0200] {dag.py:2726} INFO - Sync 1 DAGs
[2023-05-16T13:55:54.309+0200] {logging_mixin.py:149} INFO - [2023-05-16T13:55:54.309+0200] {dag.py:3486} INFO - Setting next_dagrun for etl_news_pipeline to 2023-05-16T00:00:00+00:00, run_after=2023-05-17T00:00:00+00:00
[2023-05-16T13:55:54.358+0200] {processor.py:178} INFO - Processing /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py took 6.891 seconds
[2023-05-16T13:56:26.672+0200] {processor.py:156} INFO - Started process (PID=2321) to work on /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T13:56:26.675+0200] {processor.py:799} INFO - Processing file /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py for tasks to queue
[2023-05-16T13:56:26.676+0200] {logging_mixin.py:149} INFO - [2023-05-16T13:56:26.675+0200] {dagbag.py:541} INFO - Filling up the DagBag from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T13:56:26.999+0200] {logging_mixin.py:149} INFO - [2023-05-16T13:56:26.999+0200] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2023-05-16T13:56:28.287+0200] {processor.py:809} INFO - DAG(s) dict_keys(['etl_news_pipeline']) retrieved from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T13:56:28.998+0200] {logging_mixin.py:149} INFO - [2023-05-16T13:56:28.998+0200] {dag.py:2726} INFO - Sync 1 DAGs
[2023-05-16T13:56:29.015+0200] {logging_mixin.py:149} INFO - [2023-05-16T13:56:29.014+0200] {dag.py:3486} INFO - Setting next_dagrun for etl_news_pipeline to 2023-05-16T00:00:00+00:00, run_after=2023-05-17T00:00:00+00:00
[2023-05-16T13:56:29.032+0200] {processor.py:178} INFO - Processing /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py took 2.360 seconds
[2023-05-16T13:57:00.222+0200] {processor.py:156} INFO - Started process (PID=2402) to work on /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T13:57:00.224+0200] {processor.py:799} INFO - Processing file /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py for tasks to queue
[2023-05-16T13:57:00.224+0200] {logging_mixin.py:149} INFO - [2023-05-16T13:57:00.224+0200] {dagbag.py:541} INFO - Filling up the DagBag from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T13:57:00.548+0200] {logging_mixin.py:149} INFO - [2023-05-16T13:57:00.548+0200] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2023-05-16T13:57:01.856+0200] {processor.py:809} INFO - DAG(s) dict_keys(['etl_news_pipeline']) retrieved from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T13:57:02.536+0200] {logging_mixin.py:149} INFO - [2023-05-16T13:57:02.536+0200] {dag.py:2726} INFO - Sync 1 DAGs
[2023-05-16T13:57:02.552+0200] {logging_mixin.py:149} INFO - [2023-05-16T13:57:02.552+0200] {dag.py:3486} INFO - Setting next_dagrun for etl_news_pipeline to 2023-05-16T00:00:00+00:00, run_after=2023-05-17T00:00:00+00:00
[2023-05-16T13:57:02.569+0200] {processor.py:178} INFO - Processing /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py took 2.348 seconds
[2023-05-16T13:57:33.906+0200] {processor.py:156} INFO - Started process (PID=2536) to work on /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T13:57:33.908+0200] {processor.py:799} INFO - Processing file /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py for tasks to queue
[2023-05-16T13:57:33.908+0200] {logging_mixin.py:149} INFO - [2023-05-16T13:57:33.908+0200] {dagbag.py:541} INFO - Filling up the DagBag from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T13:57:34.233+0200] {logging_mixin.py:149} INFO - [2023-05-16T13:57:34.232+0200] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2023-05-16T13:57:35.526+0200] {processor.py:809} INFO - DAG(s) dict_keys(['etl_news_pipeline']) retrieved from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T13:57:36.247+0200] {logging_mixin.py:149} INFO - [2023-05-16T13:57:36.247+0200] {dag.py:2726} INFO - Sync 1 DAGs
[2023-05-16T13:57:36.264+0200] {logging_mixin.py:149} INFO - [2023-05-16T13:57:36.264+0200] {dag.py:3486} INFO - Setting next_dagrun for etl_news_pipeline to 2023-05-16T00:00:00+00:00, run_after=2023-05-17T00:00:00+00:00
[2023-05-16T13:57:36.281+0200] {processor.py:178} INFO - Processing /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py took 2.376 seconds
[2023-05-16T13:58:01.082+0200] {processor.py:156} INFO - Started process (PID=2565) to work on /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T13:58:01.084+0200] {processor.py:799} INFO - Processing file /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py for tasks to queue
[2023-05-16T13:58:01.085+0200] {logging_mixin.py:149} INFO - [2023-05-16T13:58:01.085+0200] {dagbag.py:541} INFO - Filling up the DagBag from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T13:58:01.445+0200] {logging_mixin.py:149} INFO - [2023-05-16T13:58:01.445+0200] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2023-05-16T13:58:02.727+0200] {processor.py:809} INFO - DAG(s) dict_keys(['etl_news_pipeline']) retrieved from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T13:58:03.480+0200] {logging_mixin.py:149} INFO - [2023-05-16T13:58:03.480+0200] {dag.py:2726} INFO - Sync 1 DAGs
[2023-05-16T13:58:03.493+0200] {logging_mixin.py:149} INFO - [2023-05-16T13:58:03.493+0200] {dag.py:3486} INFO - Setting next_dagrun for etl_news_pipeline to 2023-05-16T00:00:00+00:00, run_after=2023-05-17T00:00:00+00:00
[2023-05-16T13:58:03.518+0200] {processor.py:178} INFO - Processing /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py took 2.436 seconds
[2023-05-16T13:58:34.942+0200] {processor.py:156} INFO - Started process (PID=2637) to work on /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T13:58:34.945+0200] {processor.py:799} INFO - Processing file /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py for tasks to queue
[2023-05-16T13:58:34.946+0200] {logging_mixin.py:149} INFO - [2023-05-16T13:58:34.946+0200] {dagbag.py:541} INFO - Filling up the DagBag from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T13:58:35.367+0200] {logging_mixin.py:149} INFO - [2023-05-16T13:58:35.367+0200] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2023-05-16T13:58:36.874+0200] {processor.py:809} INFO - DAG(s) dict_keys(['etl_news_pipeline']) retrieved from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T13:58:38.082+0200] {logging_mixin.py:149} INFO - [2023-05-16T13:58:38.082+0200] {dag.py:2726} INFO - Sync 1 DAGs
[2023-05-16T13:58:38.098+0200] {logging_mixin.py:149} INFO - [2023-05-16T13:58:38.098+0200] {dag.py:3486} INFO - Setting next_dagrun for etl_news_pipeline to 2023-05-16T00:00:00+00:00, run_after=2023-05-17T00:00:00+00:00
[2023-05-16T13:58:38.115+0200] {processor.py:178} INFO - Processing /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py took 3.173 seconds
[2023-05-16T13:59:09.511+0200] {processor.py:156} INFO - Started process (PID=2713) to work on /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T13:59:09.513+0200] {processor.py:799} INFO - Processing file /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py for tasks to queue
[2023-05-16T13:59:09.514+0200] {logging_mixin.py:149} INFO - [2023-05-16T13:59:09.513+0200] {dagbag.py:541} INFO - Filling up the DagBag from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T13:59:09.837+0200] {logging_mixin.py:149} INFO - [2023-05-16T13:59:09.837+0200] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2023-05-16T13:59:11.126+0200] {processor.py:809} INFO - DAG(s) dict_keys(['etl_news_pipeline']) retrieved from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T13:59:11.790+0200] {logging_mixin.py:149} INFO - [2023-05-16T13:59:11.790+0200] {dag.py:2726} INFO - Sync 1 DAGs
[2023-05-16T13:59:11.810+0200] {logging_mixin.py:149} INFO - [2023-05-16T13:59:11.810+0200] {dag.py:3486} INFO - Setting next_dagrun for etl_news_pipeline to 2023-05-16T00:00:00+00:00, run_after=2023-05-17T00:00:00+00:00
[2023-05-16T13:59:11.828+0200] {processor.py:178} INFO - Processing /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py took 2.318 seconds
[2023-05-16T13:59:43.167+0200] {processor.py:156} INFO - Started process (PID=2750) to work on /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T13:59:43.169+0200] {processor.py:799} INFO - Processing file /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py for tasks to queue
[2023-05-16T13:59:43.170+0200] {logging_mixin.py:149} INFO - [2023-05-16T13:59:43.170+0200] {dagbag.py:541} INFO - Filling up the DagBag from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T13:59:43.495+0200] {logging_mixin.py:149} INFO - [2023-05-16T13:59:43.495+0200] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2023-05-16T13:59:44.772+0200] {processor.py:809} INFO - DAG(s) dict_keys(['etl_news_pipeline']) retrieved from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T13:59:45.457+0200] {logging_mixin.py:149} INFO - [2023-05-16T13:59:45.457+0200] {dag.py:2726} INFO - Sync 1 DAGs
[2023-05-16T13:59:45.470+0200] {logging_mixin.py:149} INFO - [2023-05-16T13:59:45.470+0200] {dag.py:3486} INFO - Setting next_dagrun for etl_news_pipeline to 2023-05-16T00:00:00+00:00, run_after=2023-05-17T00:00:00+00:00
[2023-05-16T13:59:45.483+0200] {processor.py:178} INFO - Processing /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py took 2.316 seconds
[2023-05-16T14:00:16.816+0200] {processor.py:156} INFO - Started process (PID=2801) to work on /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:00:16.819+0200] {processor.py:799} INFO - Processing file /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py for tasks to queue
[2023-05-16T14:00:16.819+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:00:16.819+0200] {dagbag.py:541} INFO - Filling up the DagBag from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:00:17.155+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:00:17.155+0200] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2023-05-16T14:00:18.464+0200] {processor.py:809} INFO - DAG(s) dict_keys(['etl_news_pipeline']) retrieved from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:00:19.235+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:00:19.235+0200] {dag.py:2726} INFO - Sync 1 DAGs
[2023-05-16T14:00:19.252+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:00:19.252+0200] {dag.py:3486} INFO - Setting next_dagrun for etl_news_pipeline to 2023-05-16T00:00:00+00:00, run_after=2023-05-17T00:00:00+00:00
[2023-05-16T14:00:19.271+0200] {processor.py:178} INFO - Processing /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py took 2.455 seconds
[2023-05-16T14:00:50.557+0200] {processor.py:156} INFO - Started process (PID=2839) to work on /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:00:50.560+0200] {processor.py:799} INFO - Processing file /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py for tasks to queue
[2023-05-16T14:00:50.560+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:00:50.560+0200] {dagbag.py:541} INFO - Filling up the DagBag from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:00:50.892+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:00:50.892+0200] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2023-05-16T14:00:52.193+0200] {processor.py:809} INFO - DAG(s) dict_keys(['etl_news_pipeline']) retrieved from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:00:52.918+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:00:52.917+0200] {dag.py:2726} INFO - Sync 1 DAGs
[2023-05-16T14:00:52.934+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:00:52.934+0200] {dag.py:3486} INFO - Setting next_dagrun for etl_news_pipeline to 2023-05-16T00:00:00+00:00, run_after=2023-05-17T00:00:00+00:00
[2023-05-16T14:00:52.952+0200] {processor.py:178} INFO - Processing /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py took 2.395 seconds
[2023-05-16T14:01:24.298+0200] {processor.py:156} INFO - Started process (PID=2875) to work on /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:01:24.300+0200] {processor.py:799} INFO - Processing file /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py for tasks to queue
[2023-05-16T14:01:24.301+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:01:24.301+0200] {dagbag.py:541} INFO - Filling up the DagBag from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:01:24.630+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:01:24.629+0200] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2023-05-16T14:01:25.919+0200] {processor.py:809} INFO - DAG(s) dict_keys(['etl_news_pipeline']) retrieved from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:01:26.623+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:01:26.623+0200] {dag.py:2726} INFO - Sync 1 DAGs
[2023-05-16T14:01:26.639+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:01:26.639+0200] {dag.py:3486} INFO - Setting next_dagrun for etl_news_pipeline to 2023-05-16T00:00:00+00:00, run_after=2023-05-17T00:00:00+00:00
[2023-05-16T14:01:26.657+0200] {processor.py:178} INFO - Processing /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py took 2.359 seconds
[2023-05-16T14:43:43.531+0200] {processor.py:156} INFO - Started process (PID=5925) to work on /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:43:43.534+0200] {processor.py:799} INFO - Processing file /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py for tasks to queue
[2023-05-16T14:43:43.535+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:43:43.535+0200] {dagbag.py:541} INFO - Filling up the DagBag from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:43:44.050+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:43:44.050+0200] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2023-05-16T14:43:45.737+0200] {processor.py:809} INFO - DAG(s) dict_keys(['etl_news_pipeline']) retrieved from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:43:46.436+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:43:46.436+0200] {dag.py:2726} INFO - Sync 1 DAGs
[2023-05-16T14:43:46.453+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:43:46.453+0200] {dag.py:3486} INFO - Setting next_dagrun for etl_news_pipeline to 2023-05-16T00:00:00+00:00, run_after=2023-05-17T00:00:00+00:00
[2023-05-16T14:43:46.470+0200] {processor.py:178} INFO - Processing /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py took 2.941 seconds
[2023-05-16T14:44:17.755+0200] {processor.py:156} INFO - Started process (PID=5979) to work on /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:44:17.757+0200] {processor.py:799} INFO - Processing file /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py for tasks to queue
[2023-05-16T14:44:17.757+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:44:17.757+0200] {dagbag.py:541} INFO - Filling up the DagBag from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:44:18.104+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:44:18.104+0200] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2023-05-16T14:44:19.443+0200] {processor.py:809} INFO - DAG(s) dict_keys(['etl_news_pipeline']) retrieved from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:44:20.147+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:44:20.146+0200] {dag.py:2726} INFO - Sync 1 DAGs
[2023-05-16T14:44:20.164+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:44:20.164+0200] {dag.py:3486} INFO - Setting next_dagrun for etl_news_pipeline to 2023-05-16T00:00:00+00:00, run_after=2023-05-17T00:00:00+00:00
[2023-05-16T14:44:20.186+0200] {processor.py:178} INFO - Processing /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py took 2.432 seconds
[2023-05-16T14:44:51.540+0200] {processor.py:156} INFO - Started process (PID=6015) to work on /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:44:51.542+0200] {processor.py:799} INFO - Processing file /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py for tasks to queue
[2023-05-16T14:44:51.542+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:44:51.542+0200] {dagbag.py:541} INFO - Filling up the DagBag from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:44:51.874+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:44:51.874+0200] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2023-05-16T14:44:53.169+0200] {processor.py:809} INFO - DAG(s) dict_keys(['etl_news_pipeline']) retrieved from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:44:53.899+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:44:53.899+0200] {dag.py:2726} INFO - Sync 1 DAGs
[2023-05-16T14:44:53.917+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:44:53.917+0200] {dag.py:3486} INFO - Setting next_dagrun for etl_news_pipeline to 2023-05-16T00:00:00+00:00, run_after=2023-05-17T00:00:00+00:00
[2023-05-16T14:44:53.935+0200] {processor.py:178} INFO - Processing /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py took 2.396 seconds
[2023-05-16T14:45:25.665+0200] {processor.py:156} INFO - Started process (PID=6076) to work on /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:45:25.668+0200] {processor.py:799} INFO - Processing file /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py for tasks to queue
[2023-05-16T14:45:25.669+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:45:25.669+0200] {dagbag.py:541} INFO - Filling up the DagBag from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:45:26.206+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:45:26.206+0200] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2023-05-16T14:45:28.227+0200] {processor.py:809} INFO - DAG(s) dict_keys(['etl_news_pipeline']) retrieved from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:45:29.607+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:45:29.607+0200] {dag.py:2726} INFO - Sync 1 DAGs
[2023-05-16T14:45:29.626+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:45:29.626+0200] {dag.py:3486} INFO - Setting next_dagrun for etl_news_pipeline to 2023-05-16T00:00:00+00:00, run_after=2023-05-17T00:00:00+00:00
[2023-05-16T14:45:29.647+0200] {processor.py:178} INFO - Processing /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py took 3.983 seconds
[2023-05-16T14:46:01.087+0200] {processor.py:156} INFO - Started process (PID=6141) to work on /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:46:01.089+0200] {processor.py:799} INFO - Processing file /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py for tasks to queue
[2023-05-16T14:46:01.090+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:46:01.089+0200] {dagbag.py:541} INFO - Filling up the DagBag from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:46:01.419+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:46:01.419+0200] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2023-05-16T14:46:02.720+0200] {processor.py:809} INFO - DAG(s) dict_keys(['etl_news_pipeline']) retrieved from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:46:03.434+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:46:03.434+0200] {dag.py:2726} INFO - Sync 1 DAGs
[2023-05-16T14:46:03.452+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:46:03.452+0200] {dag.py:3486} INFO - Setting next_dagrun for etl_news_pipeline to 2023-05-16T00:00:00+00:00, run_after=2023-05-17T00:00:00+00:00
[2023-05-16T14:46:03.470+0200] {processor.py:178} INFO - Processing /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py took 2.384 seconds
[2023-05-16T14:46:31.596+0200] {processor.py:156} INFO - Started process (PID=6176) to work on /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:46:31.598+0200] {processor.py:799} INFO - Processing file /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py for tasks to queue
[2023-05-16T14:46:31.598+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:46:31.598+0200] {dagbag.py:541} INFO - Filling up the DagBag from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:46:31.923+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:46:31.923+0200] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2023-05-16T14:46:33.216+0200] {processor.py:809} INFO - DAG(s) dict_keys(['etl_news_pipeline']) retrieved from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:46:33.932+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:46:33.931+0200] {dag.py:2726} INFO - Sync 1 DAGs
[2023-05-16T14:46:33.949+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:46:33.949+0200] {dag.py:3486} INFO - Setting next_dagrun for etl_news_pipeline to 2023-05-16T00:00:00+00:00, run_after=2023-05-17T00:00:00+00:00
[2023-05-16T14:46:33.967+0200] {processor.py:178} INFO - Processing /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py took 2.372 seconds
[2023-05-16T14:47:05.341+0200] {processor.py:156} INFO - Started process (PID=6211) to work on /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:47:05.343+0200] {processor.py:799} INFO - Processing file /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py for tasks to queue
[2023-05-16T14:47:05.343+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:47:05.343+0200] {dagbag.py:541} INFO - Filling up the DagBag from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:47:05.667+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:47:05.667+0200] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2023-05-16T14:47:06.953+0200] {processor.py:809} INFO - DAG(s) dict_keys(['etl_news_pipeline']) retrieved from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:47:07.657+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:47:07.656+0200] {dag.py:2726} INFO - Sync 1 DAGs
[2023-05-16T14:47:07.673+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:47:07.673+0200] {dag.py:3486} INFO - Setting next_dagrun for etl_news_pipeline to 2023-05-16T00:00:00+00:00, run_after=2023-05-17T00:00:00+00:00
[2023-05-16T14:47:07.689+0200] {processor.py:178} INFO - Processing /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py took 2.349 seconds
[2023-05-16T14:47:25.443+0200] {processor.py:156} INFO - Started process (PID=6236) to work on /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:47:25.446+0200] {processor.py:799} INFO - Processing file /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py for tasks to queue
[2023-05-16T14:47:25.446+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:47:25.446+0200] {dagbag.py:541} INFO - Filling up the DagBag from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:47:25.783+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:47:25.783+0200] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2023-05-16T14:47:27.093+0200] {processor.py:809} INFO - DAG(s) dict_keys(['etl_news_pipeline']) retrieved from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:47:27.783+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:47:27.783+0200] {dag.py:2726} INFO - Sync 1 DAGs
[2023-05-16T14:47:27.799+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:47:27.799+0200] {dag.py:3486} INFO - Setting next_dagrun for etl_news_pipeline to 2023-05-16T00:00:00+00:00, run_after=2023-05-17T00:00:00+00:00
[2023-05-16T14:47:27.818+0200] {processor.py:178} INFO - Processing /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py took 2.375 seconds
[2023-05-16T14:47:59.158+0200] {processor.py:156} INFO - Started process (PID=6274) to work on /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:47:59.161+0200] {processor.py:799} INFO - Processing file /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py for tasks to queue
[2023-05-16T14:47:59.161+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:47:59.161+0200] {dagbag.py:541} INFO - Filling up the DagBag from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:47:59.487+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:47:59.487+0200] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2023-05-16T14:48:00.770+0200] {processor.py:809} INFO - DAG(s) dict_keys(['etl_news_pipeline']) retrieved from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:48:01.469+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:48:01.469+0200] {dag.py:2726} INFO - Sync 1 DAGs
[2023-05-16T14:48:01.485+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:48:01.485+0200] {dag.py:3486} INFO - Setting next_dagrun for etl_news_pipeline to 2023-05-16T00:00:00+00:00, run_after=2023-05-17T00:00:00+00:00
[2023-05-16T14:48:01.503+0200] {processor.py:178} INFO - Processing /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py took 2.345 seconds
[2023-05-16T14:48:32.838+0200] {processor.py:156} INFO - Started process (PID=6311) to work on /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:48:32.840+0200] {processor.py:799} INFO - Processing file /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py for tasks to queue
[2023-05-16T14:48:32.841+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:48:32.841+0200] {dagbag.py:541} INFO - Filling up the DagBag from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:48:33.166+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:48:33.166+0200] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2023-05-16T14:48:34.466+0200] {processor.py:809} INFO - DAG(s) dict_keys(['etl_news_pipeline']) retrieved from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:48:35.187+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:48:35.187+0200] {dag.py:2726} INFO - Sync 1 DAGs
[2023-05-16T14:48:35.204+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:48:35.204+0200] {dag.py:3486} INFO - Setting next_dagrun for etl_news_pipeline to 2023-05-16T00:00:00+00:00, run_after=2023-05-17T00:00:00+00:00
[2023-05-16T14:48:35.221+0200] {processor.py:178} INFO - Processing /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py took 2.384 seconds
[2023-05-16T14:49:06.569+0200] {processor.py:156} INFO - Started process (PID=6360) to work on /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:49:06.571+0200] {processor.py:799} INFO - Processing file /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py for tasks to queue
[2023-05-16T14:49:06.571+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:49:06.571+0200] {dagbag.py:541} INFO - Filling up the DagBag from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:49:06.899+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:49:06.899+0200] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2023-05-16T14:49:08.189+0200] {processor.py:809} INFO - DAG(s) dict_keys(['etl_news_pipeline']) retrieved from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:49:08.897+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:49:08.897+0200] {dag.py:2726} INFO - Sync 1 DAGs
[2023-05-16T14:49:08.917+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:49:08.917+0200] {dag.py:3486} INFO - Setting next_dagrun for etl_news_pipeline to 2023-05-16T00:00:00+00:00, run_after=2023-05-17T00:00:00+00:00
[2023-05-16T14:49:08.935+0200] {processor.py:178} INFO - Processing /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py took 2.367 seconds
[2023-05-16T14:49:40.288+0200] {processor.py:156} INFO - Started process (PID=6401) to work on /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:49:40.291+0200] {processor.py:799} INFO - Processing file /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py for tasks to queue
[2023-05-16T14:49:40.291+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:49:40.291+0200] {dagbag.py:541} INFO - Filling up the DagBag from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:49:40.623+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:49:40.623+0200] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2023-05-16T14:49:41.930+0200] {processor.py:809} INFO - DAG(s) dict_keys(['etl_news_pipeline']) retrieved from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:49:42.644+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:49:42.644+0200] {dag.py:2726} INFO - Sync 1 DAGs
[2023-05-16T14:49:42.658+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:49:42.658+0200] {dag.py:3486} INFO - Setting next_dagrun for etl_news_pipeline to 2023-05-16T00:00:00+00:00, run_after=2023-05-17T00:00:00+00:00
[2023-05-16T14:49:42.676+0200] {processor.py:178} INFO - Processing /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py took 2.388 seconds
[2023-05-16T14:50:09.009+0200] {processor.py:156} INFO - Started process (PID=6433) to work on /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:50:09.012+0200] {processor.py:799} INFO - Processing file /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py for tasks to queue
[2023-05-16T14:50:09.012+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:50:09.012+0200] {dagbag.py:541} INFO - Filling up the DagBag from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:50:09.342+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:50:09.342+0200] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2023-05-16T14:50:10.665+0200] {processor.py:809} INFO - DAG(s) dict_keys(['etl_news_pipeline']) retrieved from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:50:11.396+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:50:11.396+0200] {dag.py:2726} INFO - Sync 1 DAGs
[2023-05-16T14:50:11.415+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:50:11.415+0200] {dag.py:3486} INFO - Setting next_dagrun for etl_news_pipeline to 2023-05-16T00:00:00+00:00, run_after=2023-05-17T00:00:00+00:00
[2023-05-16T14:50:11.437+0200] {processor.py:178} INFO - Processing /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py took 2.428 seconds
[2023-05-16T14:50:24.701+0200] {processor.py:156} INFO - Started process (PID=6452) to work on /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:50:24.704+0200] {processor.py:799} INFO - Processing file /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py for tasks to queue
[2023-05-16T14:50:24.704+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:50:24.704+0200] {dagbag.py:541} INFO - Filling up the DagBag from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:50:25.027+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:50:25.027+0200] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2023-05-16T14:50:26.335+0200] {processor.py:809} INFO - DAG(s) dict_keys(['etl_news_pipeline']) retrieved from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:50:26.408+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:50:26.408+0200] {dag.py:2726} INFO - Sync 1 DAGs
[2023-05-16T14:50:27.057+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:50:27.057+0200] {dag.py:3486} INFO - Setting next_dagrun for etl_news_pipeline to 2023-05-16T00:00:00+00:00, run_after=2023-05-17T00:00:00+00:00
[2023-05-16T14:50:27.075+0200] {processor.py:178} INFO - Processing /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py took 2.374 seconds
[2023-05-16T14:50:30.156+0200] {processor.py:156} INFO - Started process (PID=6460) to work on /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:50:30.158+0200] {processor.py:799} INFO - Processing file /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py for tasks to queue
[2023-05-16T14:50:30.159+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:50:30.159+0200] {dagbag.py:541} INFO - Filling up the DagBag from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:50:30.493+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:50:30.493+0200] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2023-05-16T14:50:31.817+0200] {processor.py:809} INFO - DAG(s) dict_keys(['etl_news_pipeline']) retrieved from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:50:31.872+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:50:31.871+0200] {dag.py:2726} INFO - Sync 1 DAGs
[2023-05-16T14:50:32.498+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:50:32.497+0200] {dag.py:3486} INFO - Setting next_dagrun for etl_news_pipeline to 2023-05-16T00:00:00+00:00, run_after=2023-05-17T00:00:00+00:00
[2023-05-16T14:50:32.514+0200] {processor.py:178} INFO - Processing /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py took 2.359 seconds
[2023-05-16T14:50:52.823+0200] {processor.py:156} INFO - Started process (PID=6483) to work on /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:50:52.825+0200] {processor.py:799} INFO - Processing file /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py for tasks to queue
[2023-05-16T14:50:52.826+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:50:52.826+0200] {dagbag.py:541} INFO - Filling up the DagBag from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:50:53.158+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:50:53.158+0200] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2023-05-16T14:50:54.477+0200] {processor.py:809} INFO - DAG(s) dict_keys(['etl_news_pipeline']) retrieved from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:50:55.211+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:50:55.211+0200] {dag.py:2726} INFO - Sync 1 DAGs
[2023-05-16T14:50:55.227+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:50:55.227+0200] {dag.py:3486} INFO - Setting next_dagrun for etl_news_pipeline to 2023-05-16T00:00:00+00:00, run_after=2023-05-17T00:00:00+00:00
[2023-05-16T14:50:55.246+0200] {processor.py:178} INFO - Processing /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py took 2.424 seconds
[2023-05-16T14:51:26.570+0200] {processor.py:156} INFO - Started process (PID=6521) to work on /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:51:26.572+0200] {processor.py:799} INFO - Processing file /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py for tasks to queue
[2023-05-16T14:51:26.572+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:51:26.572+0200] {dagbag.py:541} INFO - Filling up the DagBag from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:51:26.896+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:51:26.896+0200] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2023-05-16T14:51:28.192+0200] {processor.py:809} INFO - DAG(s) dict_keys(['etl_news_pipeline']) retrieved from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:51:28.898+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:51:28.897+0200] {dag.py:2726} INFO - Sync 1 DAGs
[2023-05-16T14:51:28.913+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:51:28.913+0200] {dag.py:3486} INFO - Setting next_dagrun for etl_news_pipeline to 2023-05-16T00:00:00+00:00, run_after=2023-05-17T00:00:00+00:00
[2023-05-16T14:51:28.931+0200] {processor.py:178} INFO - Processing /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py took 2.362 seconds
[2023-05-16T14:51:40.168+0200] {processor.py:156} INFO - Started process (PID=6536) to work on /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:51:40.170+0200] {processor.py:799} INFO - Processing file /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py for tasks to queue
[2023-05-16T14:51:40.171+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:51:40.171+0200] {dagbag.py:541} INFO - Filling up the DagBag from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:51:40.514+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:51:40.514+0200] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2023-05-16T14:51:41.812+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:51:41.810+0200] {dagbag.py:350} ERROR - Failed to import: /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
Traceback (most recent call last):
  File "/Users/niyantmehta/opt/anaconda3/envs/finalvenv/lib/python3.11/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py", line 56, in <module>
    start_pipeline >> extract >> load >> etl >> end_pipeline
                                         ^^^
NameError: name 'etl' is not defined
[2023-05-16T14:51:41.812+0200] {processor.py:811} WARNING - No viable dags retrieved from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:51:42.472+0200] {processor.py:178} INFO - Processing /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py took 2.304 seconds
[2023-05-16T14:52:13.816+0200] {processor.py:156} INFO - Started process (PID=6572) to work on /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:52:13.819+0200] {processor.py:799} INFO - Processing file /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py for tasks to queue
[2023-05-16T14:52:13.819+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:52:13.819+0200] {dagbag.py:541} INFO - Filling up the DagBag from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:52:14.144+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:52:14.144+0200] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2023-05-16T14:52:15.437+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:52:15.437+0200] {dagbag.py:350} ERROR - Failed to import: /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
Traceback (most recent call last):
  File "/Users/niyantmehta/opt/anaconda3/envs/finalvenv/lib/python3.11/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py", line 56, in <module>
    start_pipeline >> extract >> load >> etl >> end_pipeline
                                         ^^^
NameError: name 'etl' is not defined
[2023-05-16T14:52:15.437+0200] {processor.py:811} WARNING - No viable dags retrieved from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:52:16.070+0200] {processor.py:178} INFO - Processing /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py took 2.255 seconds
[2023-05-16T14:52:24.888+0200] {processor.py:156} INFO - Started process (PID=6586) to work on /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:52:24.891+0200] {processor.py:799} INFO - Processing file /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py for tasks to queue
[2023-05-16T14:52:24.891+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:52:24.891+0200] {dagbag.py:541} INFO - Filling up the DagBag from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:52:25.226+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:52:25.226+0200] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2023-05-16T14:52:26.564+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:52:26.563+0200] {dagbag.py:350} ERROR - Failed to import: /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
Traceback (most recent call last):
  File "/Users/niyantmehta/opt/anaconda3/envs/finalvenv/lib/python3.11/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py", line 60, in <module>
    start_pipeline >> extract >> transform_data >> load >> end_pipeline
                                 ^^^^^^^^^^^^^^
NameError: name 'transform_data' is not defined
[2023-05-16T14:52:26.564+0200] {processor.py:811} WARNING - No viable dags retrieved from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:52:27.178+0200] {processor.py:178} INFO - Processing /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py took 2.290 seconds
[2023-05-16T14:52:30.443+0200] {processor.py:156} INFO - Started process (PID=6594) to work on /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:52:30.446+0200] {processor.py:799} INFO - Processing file /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py for tasks to queue
[2023-05-16T14:52:30.446+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:52:30.446+0200] {dagbag.py:541} INFO - Filling up the DagBag from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:52:30.778+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:52:30.778+0200] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2023-05-16T14:52:32.059+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:52:32.059+0200] {dagbag.py:350} ERROR - Failed to import: /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
Traceback (most recent call last):
  File "/Users/niyantmehta/opt/anaconda3/envs/finalvenv/lib/python3.11/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py", line 60, in <module>
    start_pipeline >> extract >> transform_data >> load >> end_pipeline
                                 ^^^^^^^^^^^^^^
NameError: name 'transform_data' is not defined
[2023-05-16T14:52:32.060+0200] {processor.py:811} WARNING - No viable dags retrieved from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:52:32.686+0200] {processor.py:178} INFO - Processing /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py took 2.243 seconds
[2023-05-16T14:53:04.051+0200] {processor.py:156} INFO - Started process (PID=6630) to work on /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:53:04.053+0200] {processor.py:799} INFO - Processing file /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py for tasks to queue
[2023-05-16T14:53:04.053+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:53:04.053+0200] {dagbag.py:541} INFO - Filling up the DagBag from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:53:04.385+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:53:04.385+0200] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2023-05-16T14:53:05.696+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:53:05.696+0200] {dagbag.py:350} ERROR - Failed to import: /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
Traceback (most recent call last):
  File "/Users/niyantmehta/opt/anaconda3/envs/finalvenv/lib/python3.11/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py", line 60, in <module>
    start_pipeline >> extract >> transform_data >> load >> end_pipeline
                                 ^^^^^^^^^^^^^^
NameError: name 'transform_data' is not defined
[2023-05-16T14:53:05.696+0200] {processor.py:811} WARNING - No viable dags retrieved from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:53:06.366+0200] {processor.py:178} INFO - Processing /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py took 2.315 seconds
[2023-05-16T14:53:37.716+0200] {processor.py:156} INFO - Started process (PID=6666) to work on /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:53:37.718+0200] {processor.py:799} INFO - Processing file /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py for tasks to queue
[2023-05-16T14:53:37.718+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:53:37.718+0200] {dagbag.py:541} INFO - Filling up the DagBag from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:53:38.048+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:53:38.048+0200] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2023-05-16T14:53:39.340+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:53:39.339+0200] {dagbag.py:350} ERROR - Failed to import: /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
Traceback (most recent call last):
  File "/Users/niyantmehta/opt/anaconda3/envs/finalvenv/lib/python3.11/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py", line 60, in <module>
    start_pipeline >> extract >> transform_data >> load >> end_pipeline
                                 ^^^^^^^^^^^^^^
NameError: name 'transform_data' is not defined
[2023-05-16T14:53:39.340+0200] {processor.py:811} WARNING - No viable dags retrieved from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:53:39.994+0200] {processor.py:178} INFO - Processing /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py took 2.279 seconds
[2023-05-16T14:54:11.358+0200] {processor.py:156} INFO - Started process (PID=6710) to work on /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:54:11.361+0200] {processor.py:799} INFO - Processing file /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py for tasks to queue
[2023-05-16T14:54:11.361+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:54:11.361+0200] {dagbag.py:541} INFO - Filling up the DagBag from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:54:11.690+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:54:11.690+0200] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2023-05-16T14:54:12.979+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:54:12.978+0200] {dagbag.py:350} ERROR - Failed to import: /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
Traceback (most recent call last):
  File "/Users/niyantmehta/opt/anaconda3/envs/finalvenv/lib/python3.11/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py", line 60, in <module>
    start_pipeline >> extract >> transform_data >> load >> end_pipeline
                                 ^^^^^^^^^^^^^^
NameError: name 'transform_data' is not defined
[2023-05-16T14:54:12.979+0200] {processor.py:811} WARNING - No viable dags retrieved from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:54:13.629+0200] {processor.py:178} INFO - Processing /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py took 2.271 seconds
[2023-05-16T14:54:30.882+0200] {processor.py:156} INFO - Started process (PID=6736) to work on /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:54:30.885+0200] {processor.py:799} INFO - Processing file /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py for tasks to queue
[2023-05-16T14:54:30.885+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:54:30.885+0200] {dagbag.py:541} INFO - Filling up the DagBag from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:54:31.265+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:54:31.264+0200] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2023-05-16T14:54:32.565+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:54:32.563+0200] {dagbag.py:350} ERROR - Failed to import: /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
Traceback (most recent call last):
  File "/Users/niyantmehta/opt/anaconda3/envs/finalvenv/lib/python3.11/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py", line 62, in <module>
    start_pipeline >> extract >> transform_data >> load >> end_pipeline
    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^~~~~~~~~~~~~~~~
  File "/Users/niyantmehta/opt/anaconda3/envs/finalvenv/lib/python3.11/site-packages/airflow/models/taskmixin.py", line 87, in __rshift__
    self.set_downstream(other)
  File "/Users/niyantmehta/opt/anaconda3/envs/finalvenv/lib/python3.11/site-packages/airflow/models/taskmixin.py", line 236, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/Users/niyantmehta/opt/anaconda3/envs/finalvenv/lib/python3.11/site-packages/airflow/models/taskmixin.py", line 181, in _set_relatives
    task_object.update_relative(self, not upstream, edge_modifier=edge_modifier)
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'function' object has no attribute 'update_relative'
[2023-05-16T14:54:32.565+0200] {processor.py:811} WARNING - No viable dags retrieved from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:54:33.231+0200] {processor.py:178} INFO - Processing /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py took 2.349 seconds
[2023-05-16T14:55:04.604+0200] {processor.py:156} INFO - Started process (PID=6796) to work on /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:55:04.606+0200] {processor.py:799} INFO - Processing file /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py for tasks to queue
[2023-05-16T14:55:04.607+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:55:04.607+0200] {dagbag.py:541} INFO - Filling up the DagBag from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:55:04.938+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:55:04.937+0200] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2023-05-16T14:55:06.242+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:55:06.241+0200] {dagbag.py:350} ERROR - Failed to import: /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
Traceback (most recent call last):
  File "/Users/niyantmehta/opt/anaconda3/envs/finalvenv/lib/python3.11/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py", line 63, in <module>
    start_pipeline >> extract >> transform_data >> load >> end_pipeline
    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^~~~~~~~~~~~~~~~
  File "/Users/niyantmehta/opt/anaconda3/envs/finalvenv/lib/python3.11/site-packages/airflow/models/taskmixin.py", line 87, in __rshift__
    self.set_downstream(other)
  File "/Users/niyantmehta/opt/anaconda3/envs/finalvenv/lib/python3.11/site-packages/airflow/models/taskmixin.py", line 236, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/Users/niyantmehta/opt/anaconda3/envs/finalvenv/lib/python3.11/site-packages/airflow/models/taskmixin.py", line 181, in _set_relatives
    task_object.update_relative(self, not upstream, edge_modifier=edge_modifier)
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'function' object has no attribute 'update_relative'
[2023-05-16T14:55:06.242+0200] {processor.py:811} WARNING - No viable dags retrieved from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:55:06.942+0200] {processor.py:178} INFO - Processing /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py took 2.339 seconds
[2023-05-16T14:55:27.200+0200] {processor.py:156} INFO - Started process (PID=6822) to work on /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:55:27.202+0200] {processor.py:799} INFO - Processing file /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py for tasks to queue
[2023-05-16T14:55:27.202+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:55:27.202+0200] {dagbag.py:541} INFO - Filling up the DagBag from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:55:27.549+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:55:27.549+0200] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2023-05-16T14:55:28.836+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:55:28.835+0200] {dagbag.py:350} ERROR - Failed to import: /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
Traceback (most recent call last):
  File "/Users/niyantmehta/opt/anaconda3/envs/finalvenv/lib/python3.11/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py", line 63, in <module>
    start_pipeline >> extract >> transform_data >> load >> end_pipeline
    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^~~~~~~~~~~~~~~~
  File "/Users/niyantmehta/opt/anaconda3/envs/finalvenv/lib/python3.11/site-packages/airflow/models/taskmixin.py", line 87, in __rshift__
    self.set_downstream(other)
  File "/Users/niyantmehta/opt/anaconda3/envs/finalvenv/lib/python3.11/site-packages/airflow/models/taskmixin.py", line 236, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/Users/niyantmehta/opt/anaconda3/envs/finalvenv/lib/python3.11/site-packages/airflow/models/taskmixin.py", line 181, in _set_relatives
    task_object.update_relative(self, not upstream, edge_modifier=edge_modifier)
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'function' object has no attribute 'update_relative'
[2023-05-16T14:55:28.836+0200] {processor.py:811} WARNING - No viable dags retrieved from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:55:29.490+0200] {processor.py:178} INFO - Processing /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py took 2.290 seconds
[2023-05-16T14:55:37.299+0200] {processor.py:156} INFO - Started process (PID=6835) to work on /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:55:37.302+0200] {processor.py:799} INFO - Processing file /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py for tasks to queue
[2023-05-16T14:55:37.303+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:55:37.302+0200] {dagbag.py:541} INFO - Filling up the DagBag from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:55:37.638+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:55:37.638+0200] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2023-05-16T14:55:38.931+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:55:38.930+0200] {dagbag.py:350} ERROR - Failed to import: /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
Traceback (most recent call last):
  File "/Users/niyantmehta/opt/anaconda3/envs/finalvenv/lib/python3.11/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py", line 64, in <module>
    start_pipeline >> extract >> transform_data >> load >> end_pipeline
    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^~~~~~~~~~~~~~~~
  File "/Users/niyantmehta/opt/anaconda3/envs/finalvenv/lib/python3.11/site-packages/airflow/models/taskmixin.py", line 87, in __rshift__
    self.set_downstream(other)
  File "/Users/niyantmehta/opt/anaconda3/envs/finalvenv/lib/python3.11/site-packages/airflow/models/taskmixin.py", line 236, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/Users/niyantmehta/opt/anaconda3/envs/finalvenv/lib/python3.11/site-packages/airflow/models/taskmixin.py", line 181, in _set_relatives
    task_object.update_relative(self, not upstream, edge_modifier=edge_modifier)
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'function' object has no attribute 'update_relative'
[2023-05-16T14:55:38.931+0200] {processor.py:811} WARNING - No viable dags retrieved from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:55:39.694+0200] {processor.py:178} INFO - Processing /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py took 2.396 seconds
[2023-05-16T14:56:11.080+0200] {processor.py:156} INFO - Started process (PID=6871) to work on /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:56:11.082+0200] {processor.py:799} INFO - Processing file /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py for tasks to queue
[2023-05-16T14:56:11.082+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:56:11.082+0200] {dagbag.py:541} INFO - Filling up the DagBag from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:56:11.415+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:56:11.415+0200] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2023-05-16T14:56:12.709+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:56:12.708+0200] {dagbag.py:350} ERROR - Failed to import: /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
Traceback (most recent call last):
  File "/Users/niyantmehta/opt/anaconda3/envs/finalvenv/lib/python3.11/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py", line 64, in <module>
    start_pipeline >> extract >> transform_data >> load >> end_pipeline
    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^~~~~~~~~~~~~~~~
  File "/Users/niyantmehta/opt/anaconda3/envs/finalvenv/lib/python3.11/site-packages/airflow/models/taskmixin.py", line 87, in __rshift__
    self.set_downstream(other)
  File "/Users/niyantmehta/opt/anaconda3/envs/finalvenv/lib/python3.11/site-packages/airflow/models/taskmixin.py", line 236, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/Users/niyantmehta/opt/anaconda3/envs/finalvenv/lib/python3.11/site-packages/airflow/models/taskmixin.py", line 181, in _set_relatives
    task_object.update_relative(self, not upstream, edge_modifier=edge_modifier)
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'function' object has no attribute 'update_relative'
[2023-05-16T14:56:12.709+0200] {processor.py:811} WARNING - No viable dags retrieved from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:56:13.381+0200] {processor.py:178} INFO - Processing /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py took 2.302 seconds
[2023-05-16T14:56:28.652+0200] {processor.py:156} INFO - Started process (PID=6891) to work on /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:56:28.654+0200] {processor.py:799} INFO - Processing file /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py for tasks to queue
[2023-05-16T14:56:28.655+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:56:28.655+0200] {dagbag.py:541} INFO - Filling up the DagBag from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:56:29.013+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:56:29.013+0200] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2023-05-16T14:56:30.355+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:56:30.355+0200] {dagbag.py:350} ERROR - Failed to import: /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
Traceback (most recent call last):
  File "/Users/niyantmehta/opt/anaconda3/envs/finalvenv/lib/python3.11/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py", line 65, in <module>
    start_pipeline >> extract >> transform_data >> load >> end_pipeline
    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^~~~~~~~~~~~~~~~
  File "/Users/niyantmehta/opt/anaconda3/envs/finalvenv/lib/python3.11/site-packages/airflow/models/taskmixin.py", line 87, in __rshift__
    self.set_downstream(other)
  File "/Users/niyantmehta/opt/anaconda3/envs/finalvenv/lib/python3.11/site-packages/airflow/models/taskmixin.py", line 236, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/Users/niyantmehta/opt/anaconda3/envs/finalvenv/lib/python3.11/site-packages/airflow/models/taskmixin.py", line 181, in _set_relatives
    task_object.update_relative(self, not upstream, edge_modifier=edge_modifier)
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'function' object has no attribute 'update_relative'
[2023-05-16T14:56:30.356+0200] {processor.py:811} WARNING - No viable dags retrieved from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:56:31.015+0200] {processor.py:178} INFO - Processing /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py took 2.361 seconds
[2023-05-16T14:56:35.232+0200] {processor.py:156} INFO - Started process (PID=6901) to work on /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:56:35.234+0200] {processor.py:799} INFO - Processing file /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py for tasks to queue
[2023-05-16T14:56:35.235+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:56:35.235+0200] {dagbag.py:541} INFO - Filling up the DagBag from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:56:35.566+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:56:35.566+0200] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2023-05-16T14:56:36.893+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:56:36.892+0200] {dagbag.py:350} ERROR - Failed to import: /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
Traceback (most recent call last):
  File "/Users/niyantmehta/opt/anaconda3/envs/finalvenv/lib/python3.11/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py", line 64, in <module>
    start_pipeline >> extract >> transform_data >> load >> end_pipeline
    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^~~~~~~~~~~~~~~~
  File "/Users/niyantmehta/opt/anaconda3/envs/finalvenv/lib/python3.11/site-packages/airflow/models/taskmixin.py", line 87, in __rshift__
    self.set_downstream(other)
  File "/Users/niyantmehta/opt/anaconda3/envs/finalvenv/lib/python3.11/site-packages/airflow/models/taskmixin.py", line 236, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/Users/niyantmehta/opt/anaconda3/envs/finalvenv/lib/python3.11/site-packages/airflow/models/taskmixin.py", line 181, in _set_relatives
    task_object.update_relative(self, not upstream, edge_modifier=edge_modifier)
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'function' object has no attribute 'update_relative'
[2023-05-16T14:56:36.893+0200] {processor.py:811} WARNING - No viable dags retrieved from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:56:37.538+0200] {processor.py:178} INFO - Processing /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py took 2.305 seconds
[2023-05-16T14:57:05.303+0200] {processor.py:156} INFO - Started process (PID=6980) to work on /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:57:05.306+0200] {processor.py:799} INFO - Processing file /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py for tasks to queue
[2023-05-16T14:57:05.306+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:57:05.306+0200] {dagbag.py:541} INFO - Filling up the DagBag from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:57:05.657+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:57:05.657+0200] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2023-05-16T14:57:07.022+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:57:07.022+0200] {dagbag.py:350} ERROR - Failed to import: /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
Traceback (most recent call last):
  File "/Users/niyantmehta/opt/anaconda3/envs/finalvenv/lib/python3.11/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py", line 64, in <module>
    start_pipeline >> extract >> transform_data >> load >> end_pipeline
    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^~~~~~~~~~~~~~~~
  File "/Users/niyantmehta/opt/anaconda3/envs/finalvenv/lib/python3.11/site-packages/airflow/models/taskmixin.py", line 87, in __rshift__
    self.set_downstream(other)
  File "/Users/niyantmehta/opt/anaconda3/envs/finalvenv/lib/python3.11/site-packages/airflow/models/taskmixin.py", line 236, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/Users/niyantmehta/opt/anaconda3/envs/finalvenv/lib/python3.11/site-packages/airflow/models/taskmixin.py", line 181, in _set_relatives
    task_object.update_relative(self, not upstream, edge_modifier=edge_modifier)
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'function' object has no attribute 'update_relative'
[2023-05-16T14:57:07.023+0200] {processor.py:811} WARNING - No viable dags retrieved from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:57:07.701+0200] {processor.py:178} INFO - Processing /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py took 2.398 seconds
[2023-05-16T14:57:39.063+0200] {processor.py:156} INFO - Started process (PID=7032) to work on /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:57:39.066+0200] {processor.py:799} INFO - Processing file /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py for tasks to queue
[2023-05-16T14:57:39.066+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:57:39.066+0200] {dagbag.py:541} INFO - Filling up the DagBag from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:57:39.390+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:57:39.390+0200] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2023-05-16T14:57:40.691+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:57:40.690+0200] {dagbag.py:350} ERROR - Failed to import: /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
Traceback (most recent call last):
  File "/Users/niyantmehta/opt/anaconda3/envs/finalvenv/lib/python3.11/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py", line 64, in <module>
    start_pipeline >> extract >> transform_data >> load >> end_pipeline
    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^~~~~~~~~~~~~~~~
  File "/Users/niyantmehta/opt/anaconda3/envs/finalvenv/lib/python3.11/site-packages/airflow/models/taskmixin.py", line 87, in __rshift__
    self.set_downstream(other)
  File "/Users/niyantmehta/opt/anaconda3/envs/finalvenv/lib/python3.11/site-packages/airflow/models/taskmixin.py", line 236, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/Users/niyantmehta/opt/anaconda3/envs/finalvenv/lib/python3.11/site-packages/airflow/models/taskmixin.py", line 181, in _set_relatives
    task_object.update_relative(self, not upstream, edge_modifier=edge_modifier)
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'function' object has no attribute 'update_relative'
[2023-05-16T14:57:40.691+0200] {processor.py:811} WARNING - No viable dags retrieved from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:57:41.337+0200] {processor.py:178} INFO - Processing /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py took 2.274 seconds
[2023-05-16T14:58:12.702+0200] {processor.py:156} INFO - Started process (PID=7069) to work on /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:58:12.704+0200] {processor.py:799} INFO - Processing file /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py for tasks to queue
[2023-05-16T14:58:12.704+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:58:12.704+0200] {dagbag.py:541} INFO - Filling up the DagBag from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:58:13.038+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:58:13.038+0200] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2023-05-16T14:58:14.338+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:58:14.337+0200] {dagbag.py:350} ERROR - Failed to import: /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
Traceback (most recent call last):
  File "/Users/niyantmehta/opt/anaconda3/envs/finalvenv/lib/python3.11/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 940, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py", line 64, in <module>
    start_pipeline >> extract >> transform_data >> load >> end_pipeline
    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^~~~~~~~~~~~~~~~
  File "/Users/niyantmehta/opt/anaconda3/envs/finalvenv/lib/python3.11/site-packages/airflow/models/taskmixin.py", line 87, in __rshift__
    self.set_downstream(other)
  File "/Users/niyantmehta/opt/anaconda3/envs/finalvenv/lib/python3.11/site-packages/airflow/models/taskmixin.py", line 236, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False, edge_modifier=edge_modifier)
  File "/Users/niyantmehta/opt/anaconda3/envs/finalvenv/lib/python3.11/site-packages/airflow/models/taskmixin.py", line 181, in _set_relatives
    task_object.update_relative(self, not upstream, edge_modifier=edge_modifier)
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'function' object has no attribute 'update_relative'
[2023-05-16T14:58:14.338+0200] {processor.py:811} WARNING - No viable dags retrieved from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:58:14.959+0200] {processor.py:178} INFO - Processing /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py took 2.258 seconds
[2023-05-16T14:58:40.844+0200] {processor.py:156} INFO - Started process (PID=7100) to work on /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:58:40.846+0200] {processor.py:799} INFO - Processing file /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py for tasks to queue
[2023-05-16T14:58:40.847+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:58:40.847+0200] {dagbag.py:541} INFO - Filling up the DagBag from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:58:41.175+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:58:41.175+0200] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2023-05-16T14:58:42.499+0200] {processor.py:809} INFO - DAG(s) dict_keys(['etl_news_pipeline']) retrieved from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:58:43.212+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:58:43.212+0200] {dag.py:2726} INFO - Sync 1 DAGs
[2023-05-16T14:58:43.230+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:58:43.230+0200] {dag.py:3486} INFO - Setting next_dagrun for etl_news_pipeline to 2023-05-16T00:00:00+00:00, run_after=2023-05-17T00:00:00+00:00
[2023-05-16T14:58:43.251+0200] {processor.py:178} INFO - Processing /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py took 2.408 seconds
[2023-05-16T14:59:15.170+0200] {processor.py:156} INFO - Started process (PID=7166) to work on /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:59:15.174+0200] {processor.py:799} INFO - Processing file /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py for tasks to queue
[2023-05-16T14:59:15.174+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:59:15.174+0200] {dagbag.py:541} INFO - Filling up the DagBag from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:59:15.681+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:59:15.681+0200] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2023-05-16T14:59:17.614+0200] {processor.py:809} INFO - DAG(s) dict_keys(['etl_news_pipeline']) retrieved from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:59:18.959+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:59:18.959+0200] {dag.py:2726} INFO - Sync 1 DAGs
[2023-05-16T14:59:18.976+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:59:18.976+0200] {dag.py:3486} INFO - Setting next_dagrun for etl_news_pipeline to 2023-05-16T00:00:00+00:00, run_after=2023-05-17T00:00:00+00:00
[2023-05-16T14:59:18.995+0200] {processor.py:178} INFO - Processing /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py took 3.826 seconds
[2023-05-16T14:59:50.464+0200] {processor.py:156} INFO - Started process (PID=7253) to work on /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:59:50.466+0200] {processor.py:799} INFO - Processing file /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py for tasks to queue
[2023-05-16T14:59:50.466+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:59:50.466+0200] {dagbag.py:541} INFO - Filling up the DagBag from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:59:50.790+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:59:50.790+0200] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2023-05-16T14:59:52.070+0200] {processor.py:809} INFO - DAG(s) dict_keys(['etl_news_pipeline']) retrieved from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T14:59:52.757+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:59:52.756+0200] {dag.py:2726} INFO - Sync 1 DAGs
[2023-05-16T14:59:52.773+0200] {logging_mixin.py:149} INFO - [2023-05-16T14:59:52.773+0200] {dag.py:3486} INFO - Setting next_dagrun for etl_news_pipeline to 2023-05-16T00:00:00+00:00, run_after=2023-05-17T00:00:00+00:00
[2023-05-16T14:59:52.790+0200] {processor.py:178} INFO - Processing /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py took 2.327 seconds
[2023-05-16T15:00:24.710+0200] {processor.py:156} INFO - Started process (PID=7319) to work on /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T15:00:24.713+0200] {processor.py:799} INFO - Processing file /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py for tasks to queue
[2023-05-16T15:00:24.714+0200] {logging_mixin.py:149} INFO - [2023-05-16T15:00:24.714+0200] {dagbag.py:541} INFO - Filling up the DagBag from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T15:00:25.223+0200] {logging_mixin.py:149} INFO - [2023-05-16T15:00:25.223+0200] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2023-05-16T15:00:27.273+0200] {processor.py:809} INFO - DAG(s) dict_keys(['etl_news_pipeline']) retrieved from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T15:00:28.634+0200] {logging_mixin.py:149} INFO - [2023-05-16T15:00:28.633+0200] {dag.py:2726} INFO - Sync 1 DAGs
[2023-05-16T15:00:28.650+0200] {logging_mixin.py:149} INFO - [2023-05-16T15:00:28.650+0200] {dag.py:3486} INFO - Setting next_dagrun for etl_news_pipeline to 2023-05-16T00:00:00+00:00, run_after=2023-05-17T00:00:00+00:00
[2023-05-16T15:00:28.670+0200] {processor.py:178} INFO - Processing /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py took 3.962 seconds
[2023-05-16T15:01:00.075+0200] {processor.py:156} INFO - Started process (PID=7409) to work on /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T15:01:00.077+0200] {processor.py:799} INFO - Processing file /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py for tasks to queue
[2023-05-16T15:01:00.077+0200] {logging_mixin.py:149} INFO - [2023-05-16T15:01:00.077+0200] {dagbag.py:541} INFO - Filling up the DagBag from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T15:01:00.405+0200] {logging_mixin.py:149} INFO - [2023-05-16T15:01:00.405+0200] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2023-05-16T15:01:01.720+0200] {processor.py:809} INFO - DAG(s) dict_keys(['etl_news_pipeline']) retrieved from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T15:01:02.473+0200] {logging_mixin.py:149} INFO - [2023-05-16T15:01:02.473+0200] {dag.py:2726} INFO - Sync 1 DAGs
[2023-05-16T15:01:02.488+0200] {logging_mixin.py:149} INFO - [2023-05-16T15:01:02.488+0200] {dag.py:3486} INFO - Setting next_dagrun for etl_news_pipeline to 2023-05-16T00:00:00+00:00, run_after=2023-05-17T00:00:00+00:00
[2023-05-16T15:01:02.511+0200] {processor.py:178} INFO - Processing /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py took 2.437 seconds
[2023-05-16T15:01:33.863+0200] {processor.py:156} INFO - Started process (PID=7446) to work on /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T15:01:33.866+0200] {processor.py:799} INFO - Processing file /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py for tasks to queue
[2023-05-16T15:01:33.866+0200] {logging_mixin.py:149} INFO - [2023-05-16T15:01:33.866+0200] {dagbag.py:541} INFO - Filling up the DagBag from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T15:01:34.193+0200] {logging_mixin.py:149} INFO - [2023-05-16T15:01:34.193+0200] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2023-05-16T15:01:35.492+0200] {processor.py:809} INFO - DAG(s) dict_keys(['etl_news_pipeline']) retrieved from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T15:01:36.230+0200] {logging_mixin.py:149} INFO - [2023-05-16T15:01:36.230+0200] {dag.py:2726} INFO - Sync 1 DAGs
[2023-05-16T15:01:36.246+0200] {logging_mixin.py:149} INFO - [2023-05-16T15:01:36.246+0200] {dag.py:3486} INFO - Setting next_dagrun for etl_news_pipeline to 2023-05-16T00:00:00+00:00, run_after=2023-05-17T00:00:00+00:00
[2023-05-16T15:01:36.266+0200] {processor.py:178} INFO - Processing /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py took 2.403 seconds
[2023-05-16T15:02:07.483+0200] {processor.py:156} INFO - Started process (PID=7484) to work on /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T15:02:07.485+0200] {processor.py:799} INFO - Processing file /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py for tasks to queue
[2023-05-16T15:02:07.486+0200] {logging_mixin.py:149} INFO - [2023-05-16T15:02:07.485+0200] {dagbag.py:541} INFO - Filling up the DagBag from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T15:02:07.826+0200] {logging_mixin.py:149} INFO - [2023-05-16T15:02:07.826+0200] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2023-05-16T15:02:09.120+0200] {processor.py:809} INFO - DAG(s) dict_keys(['etl_news_pipeline']) retrieved from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T15:02:09.827+0200] {logging_mixin.py:149} INFO - [2023-05-16T15:02:09.827+0200] {dag.py:2726} INFO - Sync 1 DAGs
[2023-05-16T15:02:09.845+0200] {logging_mixin.py:149} INFO - [2023-05-16T15:02:09.844+0200] {dag.py:3486} INFO - Setting next_dagrun for etl_news_pipeline to 2023-05-16T00:00:00+00:00, run_after=2023-05-17T00:00:00+00:00
[2023-05-16T15:02:09.865+0200] {processor.py:178} INFO - Processing /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py took 2.382 seconds
[2023-05-16T15:02:41.230+0200] {processor.py:156} INFO - Started process (PID=7525) to work on /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T15:02:41.232+0200] {processor.py:799} INFO - Processing file /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py for tasks to queue
[2023-05-16T15:02:41.232+0200] {logging_mixin.py:149} INFO - [2023-05-16T15:02:41.232+0200] {dagbag.py:541} INFO - Filling up the DagBag from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T15:02:41.566+0200] {logging_mixin.py:149} INFO - [2023-05-16T15:02:41.566+0200] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2023-05-16T15:02:42.873+0200] {processor.py:809} INFO - DAG(s) dict_keys(['etl_news_pipeline']) retrieved from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T15:02:43.597+0200] {logging_mixin.py:149} INFO - [2023-05-16T15:02:43.596+0200] {dag.py:2726} INFO - Sync 1 DAGs
[2023-05-16T15:02:43.614+0200] {logging_mixin.py:149} INFO - [2023-05-16T15:02:43.614+0200] {dag.py:3486} INFO - Setting next_dagrun for etl_news_pipeline to 2023-05-16T00:00:00+00:00, run_after=2023-05-17T00:00:00+00:00
[2023-05-16T15:02:43.634+0200] {processor.py:178} INFO - Processing /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py took 2.405 seconds
[2023-05-16T15:03:14.983+0200] {processor.py:156} INFO - Started process (PID=7564) to work on /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T15:03:14.985+0200] {processor.py:799} INFO - Processing file /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py for tasks to queue
[2023-05-16T15:03:14.985+0200] {logging_mixin.py:149} INFO - [2023-05-16T15:03:14.985+0200] {dagbag.py:541} INFO - Filling up the DagBag from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T15:03:15.315+0200] {logging_mixin.py:149} INFO - [2023-05-16T15:03:15.315+0200] {utils.py:160} INFO - NumExpr defaulting to 8 threads.
[2023-05-16T15:03:16.620+0200] {processor.py:809} INFO - DAG(s) dict_keys(['etl_news_pipeline']) retrieved from /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py
[2023-05-16T15:03:17.340+0200] {logging_mixin.py:149} INFO - [2023-05-16T15:03:17.340+0200] {dag.py:2726} INFO - Sync 1 DAGs
[2023-05-16T15:03:17.357+0200] {logging_mixin.py:149} INFO - [2023-05-16T15:03:17.357+0200] {dag.py:3486} INFO - Setting next_dagrun for etl_news_pipeline to 2023-05-16T00:00:00+00:00, run_after=2023-05-17T00:00:00+00:00
[2023-05-16T15:03:17.376+0200] {processor.py:178} INFO - Processing /Users/niyantmehta/Spiced/ETL_Pipeline/airflow/ETL_dags/etl_pipeline.py took 2.394 seconds
